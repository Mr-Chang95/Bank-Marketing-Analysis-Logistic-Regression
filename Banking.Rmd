---
title: "bank"
author: "Daniel Chang"
date: "2023-04-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Data and Packages

```{r bank}
library(tidyverse)
library(GGally)
library(skimr)
library(reshape2)
library(caret)
library(olsrr)
library(car)
library(glmnet)
library(pROC)
library(ResourceSelection)
library(MASS)
library(class)

bank = read.csv("bank-full.csv", stringsAsFactors = T)
head(bank)
```

```{r}
summary(bank)
```

There are a total of 45211 rows and 17 columns. 
```{r}
# Look at structure
str(bank)
# Skim the dataset
skim(bank)
```
### Check for missing values 

No null data in our dataset. 

```{r}
colSums(is.na(bank))
sum(is.na(bank))
```

## Objective 1
### Exploratory Data Analysis(EDA)

Looking at the subscription count, we can see that we have heavily imbalanced dataset.There are almost 40k Nos while there is about about 5k Yes's.

There are several plots that are noteworthy. One is the housing barplot. Even though, we see that the number of count for those with no housing is lower, the subscription count is higher. 

```{r EDA, message = F}
# yes or no subscruption count
ggplot(bank, aes(x = y)) +
  geom_bar() 

# Job Count
ggplot(bank, aes(x = job, fill = y)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

# Education Count
ggplot(bank, aes(x = education, fill = y)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

# Age Distribution
ggplot(bank, aes(x = age, fill = y)) +
  geom_histogram(bins = 50)

# Duration Distribution
ggplot(bank, aes(x = duration, fill = y)) +
  geom_histogram(bins = 50)

# Balance Distribution
ggplot(bank, aes(x = balance, fill = y)) +
  geom_histogram(bins = 20)

# Housing Count
ggplot(bank, aes(x = housing, fill = y)) +
  geom_bar()

# Loan 
ggplot(data = bank, aes(x = loan , fill = y)) + 
  geom_bar(stat = 'count', position = 'dodge') + 
  xlab("Loan")+ylab("Response")

# Marital Status 
ggplot(data = bank, aes(x = marital, fill = y)) + 
  geom_bar(stat = 'count', position = 'dodge') + 
  xlab("Marital")+ylab("Response")

# Default
ggplot(data = bank, aes(x = default ,  fill = y)) + 
  geom_bar(stat = 'count', position = 'dodge') + 
  xlab("Default")+ylab("Response")

# Default
ggplot(data = bank, aes(x = poutcome ,  fill = y)) + 
  geom_bar(stat = 'count', position = 'dodge') + 
  xlab("Poutcome")+ylab("Response")

# Previous 
ggplot(data = bank, aes(x = previous, fill = y)) +
  geom_histogram() +
  labs(title = "Distribution of Previous Campaign", 
       x = "Previous Campaign", y = "Count")
```

### Correlation Matrix

After creating a dummy column to make our y column numeric, we can see that there is hardly any correlation between our response variable and the other variables. The strongest relationship is y_num and duration at 0.395. 

```{r Corr Matrix, message = FALSE}
# make new numeric column for "y" column
bank$y_num = num(ifelse(bank$y == "yes",1,0))

## Correlation map
num_cols = unlist(lapply(bank, is.numeric))
data_num = bank[ , num_cols] 
corr_mat = round(cor(data_num),2)
 
# reduce the size of correlation matrix
melted_corr_mat = melt(corr_mat)
# head(melted_corr_mat)
 
# plotting the correlation heatmap
ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2,
                                   fill=value)) +
geom_tile() +
geom_text(aes(Var2, Var1, label = value),
          color = "white", size = 4) +
  ggtitle("Heatmap of Correalation For Numeric Variables")

# ggpairs
ggpairs(data_num)
```

### LOESS 
```{r}
# Age (check)
ggplot(bank,aes(x=age,y=y_num))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)

# Balance
ggplot(bank,aes(x=balance,y=y_num))+geom_point()+
  geom_smooth(method="loess",size=1,span=0.1, se = FALSE)

# Duration (maybe add poly to it)
ggplot(bank,aes(x=duration,y=y_num))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)

# Pdays (check)
ggplot(bank,aes(x=pdays,y=y_num))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE)

# campaign 
ggplot(bank,aes(x=campaign,y=y_num))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE)

# day
ggplot(bank,aes(x=day,y=y_num))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE)
```

### Base Model 

AUROC:          0.9085
LogLoss:        0.2409315
AIC:            15206
Accuracy:       0.814
Sensitivity:    0.8064
Specificity:    0.8714

Note that because we have such unbalanced data, our accuracy is always expected to be high. Only 10% of the results were "yes", so just picking "no" 100% of the time would result in an accuracy of 90%.

However, once we try and increase the specificity, we realize that the ideal threshold for this base model is 0.096, which reduces our accuracy down to 81%. The decrease in accuracy results in a much better improvement and equality in sensitivity and specificity.

```{r}
bank = bank[,-c(18)] # remove y_num from dataset

set.seed(124)
trainIndex = createDataPartition(bank$y, p= .7, list = F) 
training = bank[trainIndex,]
test = bank[-trainIndex,]

model1 = glm(factor(y)~., data = training, family = "binomial")
summary(model1)
vif(model1)

fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
logit_base = train(factor(y) ~ ., data = training, method = "glm", trControl = fitControl, metric = "logLoss")
summary(logit_base$finalModel)
length(predictors(logit_base))

# Generate an ROC curve to help us determine the best threshold
logit_base_predictions = predict(logit_base, test, type = "prob")$yes
logit_base_roc = roc(response = test$y, predictor = logit_base_predictions, levels = c("no", "yes"))
auc(logit_base_roc)
plot(logit_base_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.096
logit_base_predictions_categorical = factor(ifelse(predict(logit_base, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = logit_base_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```


### Adjusted Base Model(GLM-Net) 

We remove the insignificant variables from `summary(model1)`. 

AUROC:          0.9087
AIC:            15203
Accuracy:       0.8082
Sensitivity:    0.7987
Specificity:    0.8802

However, once we try and increase the specificity, we realize that the ideal threshold for this base model is 0.093, which reduces our accuracy down to 80.82% which is lower than our base model. We see that our sensitivity suffered heavily but our specificity increased slightly. 

```{r}
training1 = training[,-c(1,5,14,15)]
adj.model1 = glm(factor(y)~., data = training1, family = "binomial")
summary(adj.model1)
vif(adj.model1)

fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
fit.adj = train(factor(y) ~ ., data = training1, method = "glm", trControl = fitControl, metric = "logLoss")
summary(fit.adj$finalModel)
length(predictors(fit.adj))

# Generate an ROC curve to help us determine the best threshold
fit.adj_predictions = predict(fit.adj, test, type = "prob")$yes
fit.adj_roc = roc(response = test$y, predictor = fit.adj_predictions, levels = c("no", "yes"))
auc(fit.adj_roc)
plot(fit.adj_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.093
fit.adj_predictions_categorical = factor(ifelse(predict(fit.adj, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = fit.adj_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```


### Penalized Regression/LASSO
```{r}
fitControl=trainControl(method="repeatedcv",number=5,repeats=1) 

set.seed(124)

lambda=seq(0,.05,.001)
fit.glmnet = train(factor(y)~.,
                 data = training,
                 method = "glmnet",
                 trControl = fitControl,
                 tuneGrid = expand.grid(data.frame(alpha = 1, lambda = lambda)))
fit.glmnet

plot(fit.glmnet)
opt.pen= fit.glmnet$finalModel$lambdaOpt
coef(fit.glmnet$finalModel, opt.pen)
```

```{r}
training2 = training[,-c(1,5,14)]
pen.model1 = glm(factor(y)~., data = training2, family = "binomial")
summary(pen.model1)
vif(pen.model1)
```


```{r}
# Generate an ROC curve to help us determine the best threshold
fit.glmnet_predictions = predict(fit.glmnet, test, type = "prob")$yes
fit.glmnet_roc = roc(response = test$y, predictor = fit.glmnet_predictions, levels = c("no", "yes"))
auc(fit.glmnet_roc)
plot(fit.glmnet_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.107
fit.glmnet_predictions_categorical = factor(ifelse(predict(fit.glmnet, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = fit.glmnet_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```


### Stepwise Feature Selection
```{r}
set.seed(124)
fit.step  = glm(factor(y) ~., data = training, family = binomial) %>%
  stepAIC(trace = FALSE)
summary(fit.step)

coef(fit.step)
vif(fit.step)

# Generate an ROC curve to help us determine the best threshold
fit.step_predictions = predict(fit.step, test, type = "response")
fit.step_roc = roc(response = test$y, predictor = fit.step_predictions, levels = c("no", "yes"))
auc(fit.step_roc)
plot(fit.step_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.093
fit.step_predictions_categorical = factor(ifelse(predict(fit.step, test, "response") >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = fit.step_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```

### Manual Stepwise
```{r}
set.seed(124)
stepwiseResults = read.csv("Stepwise Regression Results.csv")

ggplot(stepwiseResults, aes(x = reorder(Variable.Added, AIC, decreasing = T), y = AIC)) + 
  geom_point(size = 3) +
  labs(title = "AIC Metric with Additional Variables being Added", x= "Variable Added", y = "AIC") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

logit_step = glm(factor(y) ~ housing + contact + month + duration + poutcome , data = training, family = "binomial")
summary(logit_step)
vif(logit_step)

# Generate an ROC curve to help us determine the best threshold
logit_step_predictions = predict(logit_step, test, type = "response")
logit_step_roc = roc(response = test$y, predictor = logit_step_predictions, levels = c("no", "yes"))
auc(logit_step_roc)
plot(logit_step_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.101
logit_step_predictions_categorical = factor(ifelse(predict(logit_step, test, "response") >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = logit_step_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```

### AIC Comparison 
```{r}
AIC(model1)
AIC(adj.model1)
AIC(pen.model1)
AIC(fit.step)
AIC(logit_step)

anova(logit_step, pen.model1, test = "Chisq")
```


```{r}
model1.coef= coef(model1) # normal coefficient output
model1.coef

model1.OR = exp(coef(model1)) # exp coefficient
model1.OR

# confidence intervals
model1.ci = exp(confint(model1, level = .95)) # confidence interval @ .05 significance
model1.ci
```

```{r}
anova(pen.model1, fit.step)
hoslem.test(pen.model1$y,fitted(pen.model1),g=10)
hoslem.test(logit_step$y,fitted(logit_step),g=10)
```

## Objective 2

### EDA
```{r}
## Age
ggplot(bank,aes(x=age,y=y_num, color = marital))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)

ggplot(bank,aes(x=age,y=y_num, color = education))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE) # no difference 

ggplot(bank,aes(x=age,y=y_num, color = housing))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)

ggplot(bank,aes(x=age,y=y_num, color = loan))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)


## Balance
ggplot(bank,aes(x=balance,y=y_num, color = marital))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)

ggplot(bank,aes(x=balance,y=y_num, color = housing))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE) # no difference

ggplot(bank,aes(x=balance,y=y_num, color = education))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)

ggplot(bank,aes(x=balance,y=y_num, color = loan))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)

## Duration
ggplot(bank,aes(x=duration,y=y_num, color = marital))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)

ggplot(bank,aes(x=duration,y=y_num, color = housing))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)

ggplot(bank,aes(x=duration,y=y_num, color = education))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)

ggplot(bank,aes(x=duration,y=y_num, color = loan))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)

## Pdays
ggplot(bank,aes(x=pdays,y=y_num, color = marital))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE)

ggplot(bank,aes(x=pdays,y=y_num, color = housing))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE)

ggplot(bank,aes(x=pdays,y=y_num, color = education))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE)

ggplot(bank,aes(x=pdays,y=y_num, color = loan))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE)
```

### 1. More complicated logistic regression model

```{r}
logit_complex = glm(factor(y) ~ poutcome + log(duration + 1) + poutcome:log(duration + 1) + month + month:log(duration + 1) + contact + housing + housing:log(duration + 1) + job + campaign + campaign:log(duration + 1) + loan + loan:log(duration + 1) + marital + marital:log(duration + 1) + education + day + balance + previous, 
                    data = training, family = "binomial")
summary(logit_complex)

# Generate an ROC curve to help us determine the best threshold
logit_complex_predictions = predict(logit_complex, test, type = "response")
logit_complex_roc = roc(response = test$y, predictor = logit_complex_predictions, levels = c("no", "yes"))
auc(logit_complex_roc)
plot(logit_complex_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.12
logit_complex_predictions_categorical = factor(ifelse(predict(logit_complex, test, "response") >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = logit_complex_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```

### 2. LDA/QDA

```{r}
training %>% ggplot(aes(x =age,y = balance, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =age,y = day, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =age,y = duration, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =age,y = campaign, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =balance,y = day, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =balance,y = duration, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =balance,y = campaign, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =day,y = duration, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =day,y = campaign, color = as.factor(y))) + 
  geom_point()+geom_density_2d()
```

```{r}
set.seed(1234)
fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
lda_base = train(factor(y) ~ ., data = training, method = "lda", trControl = fitControl, metric = "logLoss")
summary(lda_base)

# Generate an ROC curve to help us determine the best threshold
lda_base_predictions = predict(lda_base, test, type = "prob")$yes
lda_base_roc = roc(response = test$y, predictor = lda_base_predictions, levels = c("no", "yes"))
auc(lda_base_roc)
plot(lda_base_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.045
lda_base_predictions_categorical = factor(ifelse(predict(lda_base, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = lda_base_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```

NOTE: QDA does not perform very well here. The optimal threshold was 0 which returns NaN's in certain performance metrics

```{r}
set.seed(1234)
fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
qda_base = train(factor(y) ~ ., data = training, method = "qda", trControl = fitControl, metric = "logLoss")
summary(qda_base)

# Generate an ROC curve to help us determine the best threshold
qda_base_predictions = predict(qda_base, test, type = "prob")$yes
qda_base_roc = roc(response = test$y, predictor = qda_base_predictions, levels = c("no", "yes"))
auc(qda_base_roc)
plot(qda_base_roc, print.thres = "best", col = "black")

# Predict
threshold = 0
qda_base_predictions_categorical = factor(ifelse(predict(qda_base, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = qda_base_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```


### 3. Non-parametric model

#### KNN Model
```{r}
## KNN 
set.seed(1234)
fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
knn.base = train(factor(y) ~ ., data = training, method = "knn", trControl = fitControl, metric = "logLoss")

# Generate an ROC curve to help us determine the best threshold
knn.base_predictions = predict(knn.base, test, type = "prob")$yes
knn.base_roc = roc(response = test$y, predictor = knn.base_predictions, levels = c("no", "yes"))
auc(knn.base_roc)
plot(knn.base_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.211
knn.base_predictions_categorical = factor(ifelse(predict(knn.base, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = knn.base_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```

#### Random Forest Model
```{r}
## Random Forest
set.seed(1234)
fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
rf.base = train(factor(y) ~ ., data = training, method = "rf", trControl = fitControl, metric = "logLoss")
summary(rf.base)

# Generate an ROC curve to help us determine the best threshold
rf.base_predictions = predict(rf.base, test, type = "prob")$yes
rf.base_roc = roc(response = test$y, predictor = rf.base_predictions, levels = c("no", "yes"))
auc(rf.base_roc)
plot(rf.base_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.123
rf.base_predictions_categorical = factor(ifelse(predict(rf.base, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = rf.base_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```

#### eXtreme Gradient Boosting 
```{r}
## XGB
set.seed(1234)
fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
xgb.base = train(factor(y) ~ ., data = training, method = "xgbTree", trControl = fitControl, metric = "logLoss")
summary(xgb.base)

# Generate an ROC curve to help us determine the best threshold
xgb.base_predictions = predict(xgb.base, test, type = "prob")$yes
xgb.base_roc = roc(response = test$y, predictor = xgb.base_predictions, levels = c("no", "yes"))
auc(xgb.base_roc)
plot(xgb.base_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.096
xgb.base_predictions_categorical = factor(ifelse(predict(xgb.base, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = xgb.base_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```

### Check All Models AIC
```{r}
AIC(model1)
AIC(adj.model1)
AIC(pen.model1)
AIC(fit.step)
AIC(logit_step)
AIC(logit_complex)
```