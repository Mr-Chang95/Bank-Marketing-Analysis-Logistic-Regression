---
title: "bank"
author: "Daniel Chang"
date: "2023-04-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Data and Packages

```{r bank}
library(tidyverse)
library(GGally)
library(skimr)
library(reshape2)
library(caret)
library(olsrr)
library(car)
library(glmnet)
library(pROC)
library(ResourceSelection)
library(MASS)
library(class)
#library(gtsummary)

bank = read.csv("bank-full.csv", stringsAsFactors = T)
head(bank)
```

```{r}
summary(bank)
```

There are a total of 45211 rows and 17 columns. 
```{r}
# Look at structure
str(bank)
# Skim the dataset
skim(bank)

```
### Check for missing values 

No null data in our dataset. 

```{r}
colSums(is.na(bank))
sum(is.na(bank))
```

## Objective 1
### Exploratory Data Analysis(EDA)

Looking at the subscription count, we can see that we have heavily imbalanced dataset.There are almost 40k Nos while there is about about 5k Yes's.

There are several plots that are noteworthy. One is the housing barplot. Even though, we see that the number of count for those with no housing is lower, the subscription count is higher. 

```{r EDA, message = F}
# yes or no subscruption count
ggplot(bank, aes(x = y)) +
  geom_bar() 

# Job Count
ggplot(bank, aes(x = job, fill = y)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + ggtitle("Subscriptions vs. Job Count")

# Education Count
ggplot(bank, aes(x = education, fill = y)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + ggtitle("Subscriptions vs. Education Count")

# Age Distribution
ggplot(bank, aes(x = age, fill = y)) +
  geom_histogram(bins = 50) + ggtitle("Subscriptions vs. Age Distribution")

# Duration Distribution
ggplot(bank, aes(x = duration, fill = y)) +
  geom_histogram(bins = 50) + ggtitle("Subscriptions vs. Duration Distribution")
ggplot(bank, aes(x = log(duration), fill = y)) +
  geom_histogram(bins = 50) + ggtitle("Subscriptions vs. log(Duration) Distribution")

# Balance Distribution
ggplot(bank, aes(x = balance, fill = y)) +
  geom_histogram(bins = 20) + ggtitle("Subscriptions vs. Balance Distribution")

# Housing Count
ggplot(bank, aes(x = housing, fill = y)) +
  geom_bar() + ggtitle("Subscriptions vs. Housing Count")

# Loan 
ggplot(data = bank, aes(x = loan , fill = y)) + 
  geom_bar(stat = 'count', position = 'dodge') + 
  xlab("Loan")+ylab("Response") + ggtitle("Subscriptions vs. Loans")

# Marital Status 
ggplot(data = bank, aes(x = marital, fill = y)) + 
  geom_bar(stat = 'count', position = 'dodge') + 
  xlab("Marital")+ylab("Response") + ggtitle("Subscriptions vs. Marital Status")

# Default
ggplot(data = bank, aes(x = default ,  fill = y)) + 
  geom_bar(stat = 'count', position = 'dodge') + 
  xlab("Default")+ylab("Response") + ggtitle("Subscriptions vs. Default")

# Poutcome
ggplot(data = bank, aes(x = poutcome ,  fill = y)) + 
  geom_bar(stat = 'count', position = 'dodge') + 
  xlab("Poutcome")+ylab("Response") + ggtitle("Subscriptions vs. Previous Outcome")

# Previous 
ggplot(data = bank, aes(x = previous, fill = y)) +
  geom_histogram() +
  labs(title = "Distribution of Previous Campaign", 
       x = "Previous Campaign", y = "Count") 
```

```{r, fig.width=11}
library(dplyr)
# group jobs by percent 
g1<-bank %>% 
  group_by(job,y) %>%
  summarise(cnt=n()) %>%
  mutate(perc=round(cnt/sum(cnt),4))%>%
  arrange(desc(perc))

# Both Yes & No
# ggplot(g1,aes(x=reorder(job,-perc),y=perc,colour=y))+
#   geom_bar(aes(fill=y),show.legend=T,stat="identity") + ylab("Proportion of Subscriptions") + xlab("Job Type") + ggtitle("Propotion Subscriptions vs. Job Type")

ggplot(g1[13:24,],aes(x=reorder(job,-perc),y=perc,colour=job))+
  geom_bar(aes(fill=job),show.legend=T,stat="identity") + ylab("Proportion of Subscriptions") + xlab("Job Type") + ggtitle("Propotion Subscriptions vs. Job Type")

# group poutcome by percent
g2<-bank %>% 
  group_by(poutcome,y) %>%
  summarise(cnt=n()) %>%
  mutate(perc=round(cnt/sum(cnt),4))%>%
  arrange(desc(perc))

# ggplot(g2,aes(x=reorder(poutcome,-perc),y=perc,colour=y))+
#   geom_bar(aes(fill=y),show.legend=T,stat="identity")  + ylab("Proportion of Subscriptions") + xlab("Previous Outcome") + ggtitle(" Proportion of Subscriptions vs. Previous Outcome")

ggplot(g2[c(4, 6, 7, 8),],aes(x=reorder(poutcome,-perc),y=perc,colour=poutcome))+
  geom_bar(aes(fill=poutcome),show.legend=T,stat="identity")  + ylab("Proportion of Subscriptions") + xlab("Previous Outcome") + ggtitle(" Proportion of Subscriptions vs. Previous Outcome")

# group default by percent 
g3<-bank %>% 
  group_by(default,y) %>%
  summarise(cnt=n()) %>%
  mutate(perc=round(cnt/sum(cnt),4))%>%
  arrange(desc(perc))

ggplot(g3,aes(x=reorder(default,-perc),y=perc,colour=y))+
  geom_bar(aes(fill=y),show.legend=T,stat="identity")  + ylab("Proportion of Subscriptions") + xlab("Default") + ggtitle(" Proportion of Subscriptions vs. Default")

# group month by proportion 
g4<-bank %>% 
  group_by(month,y) %>%
  summarise(cnt=n()) %>%
  mutate(perc=round(cnt/sum(cnt),4))%>%
  arrange(desc(perc))

# ggplot(g4,aes(x=reorder(month,-perc),y=perc,colour=y))+
#   geom_bar(aes(fill=y),show.legend=T,stat="identity")  + ylab("Proportion of Subscriptions") + xlab("Month") + ggtitle(" Proportion of Subscriptions vs. Month")
ggplot(g4[c(12,14:24),],aes(x=reorder(month,-perc),y=perc,colour=month))+
  geom_bar(aes(fill=month),show.legend=T,stat="identity")  + ylab("Proportion of Subscriptions") + xlab("Month") + ggtitle(" Proportion of Subscriptions vs. Month")

# group education by proportion 
g5 <-bank %>% 
  group_by(education,y) %>%
  summarise(cnt=n()) %>%
  mutate(perc=round(cnt/sum(cnt),4))%>%
  arrange(desc(perc))
g5
ggplot(g5[c(5:8),],aes(x=reorder(education,-perc),y=perc,colour=education))+
  geom_bar(aes(fill=education),show.legend=T,stat="identity")  + ylab("Proportion of Subscriptions") + xlab("Month") + ggtitle(" Proportion of Subscriptions vs. Month")

# group marital status by proportion 
g6 <-bank %>% 
  group_by(marital,y) %>%
  summarise(cnt=n()) %>%
  mutate(perc=round(cnt/sum(cnt),4))%>%
  arrange(desc(perc))
g6
ggplot(g6[c(4:6),],aes(x=reorder(marital,-perc),y=perc,colour=marital))+
  geom_bar(aes(fill=marital),show.legend=T,stat="identity")  + ylab("Proportion of Subscriptions") + xlab("Month") + ggtitle(" Proportion of Subscriptions vs. Marital")
```


### Correlation Matrix

After creating a dummy column to make our y column numeric, we can see that there is hardly any correlation between our response variable and the other variables. The strongest relationship is y_num and duration at 0.395. 

```{r Corr Matrix, message = FALSE}
# make new numeric column for "y" column
bank$y_num = num(ifelse(bank$y == "yes",1,0))

## Correlation map
num_cols = unlist(lapply(bank, is.numeric))
data_num = bank[ , num_cols] 
corr_mat = round(cor(data_num),2)
 
# reduce the size of correlation matrix
melted_corr_mat = melt(corr_mat)
# head(melted_corr_mat)
 
# plotting the correlation heatmap
ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2,
                                   fill=value)) +
geom_tile() +
geom_text(aes(Var2, Var1, label = value),
          color = "white", size = 4) +
  ggtitle("Heatmap of Correalation For Numeric Variables")

# ggpairs
ggpairs(data_num)
```

### LOESS 
```{r}
# Age (check)
ggplot(bank,aes(x=age,y=y_num))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE) + ggtitle("Age vs. Subscription Loess Plot")

# Balance
ggplot(bank,aes(x=balance,y=y_num))+geom_point()+
  geom_smooth(method="loess",size=1,span=0.1, se = FALSE) + ggtitle("Balance vs. Subscription Loess Plot")

# Duration (maybe add poly to it)
ggplot(bank,aes(x=duration,y=y_num))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE) + ggtitle("Duration vs. Subscription Loess Plot")

# Pdays (check)
ggplot(bank,aes(x=pdays,y=y_num))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE) + ggtitle("Pdays vs. Subscription Loess Plot")

# campaign 
ggplot(bank,aes(x=campaign,y=y_num))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE) + ggtitle("Campain vs. Subscription Loess Plot")

# day
ggplot(bank,aes(x=day,y=y_num))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE) + ggtitle("Day vs. Subscription Loess Plot")
```

### Base Model 

AUROC:          0.9085
LogLoss:        0.2409315
AIC:            15206
Accuracy:       0.814
Sensitivity:    0.8064
Specificity:    0.8714

Note that because we have such unbalanced data, our accuracy is always expected to be high. Only 10% of the results were "yes", so just picking "no" 100% of the time would result in an accuracy of 90%.

However, once we try and increase the specificity, we realize that the ideal threshold for this base model is 0.096, which reduces our accuracy down to 81%. The decrease in accuracy results in a much better improvement and equality in sensitivity and specificity.

```{r}
bank = bank[,-c(18)] # remove y_num from dataset

set.seed(124)
trainIndex = createDataPartition(bank$y, p= .7, list = F) 
training = bank[trainIndex,]
test = bank[-trainIndex,]

model1 = glm(factor(y)~., data = training, family = "binomial")
summary(model1)
vif(model1)

fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
logit_base = train(factor(y) ~ ., data = training, method = "glm", trControl = fitControl, metric = "logLoss")
summary(logit_base$finalModel)
length(predictors(logit_base))

# Generate an ROC curve to help us determine the best threshold
logit_base_predictions = predict(logit_base, test, type = "prob")$yes
logit_base_roc = roc(response = test$y, predictor = logit_base_predictions, levels = c("no", "yes"))
auc(logit_base_roc)
plot(logit_base_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.096
logit_base_predictions_categorical = factor(ifelse(predict(logit_base, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = logit_base_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```


### Adjusted Base Model(GLM-Net) 

We remove the insignificant variables from `summary(model1)`. 

AUROC:          0.9087
AIC:            15203
Accuracy:       0.8082
Sensitivity:    0.7987
Specificity:    0.8802

However, once we try and increase the specificity, we realize that the ideal threshold for this base model is 0.093, which reduces our accuracy down to 80.82% which is lower than our base model. We see that our sensitivity suffered heavily but our specificity increased slightly. 

```{r}
training1 = training[,-c(1,5,14,15)]
adj.model1 = glm(factor(y)~., data = training1, family = "binomial")
summary(adj.model1)
vif(adj.model1)

fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
fit.adj = train(factor(y) ~ ., data = training1, method = "glm", trControl = fitControl, metric = "logLoss")
summary(fit.adj$finalModel)
length(predictors(fit.adj))

# Generate an ROC curve to help us determine the best threshold
fit.adj_predictions = predict(fit.adj, test, type = "prob")$yes
fit.adj_roc = roc(response = test$y, predictor = fit.adj_predictions, levels = c("no", "yes"))
auc(fit.adj_roc)
plot(fit.adj_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.093
fit.adj_predictions_categorical = factor(ifelse(predict(fit.adj, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = fit.adj_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```


### Penalized Regression/LASSO

AUROC:          0.9102
AIC:            15201.86
Accuracy:       0.8289
Sensitivity:    0.8258
Specificity:    0.8525

Note that because we have such unbalanced data, our accuracy is always expected to be high. Only 10% of the results were "yes", so just picking "no" 100% of the time would result in an accuracy of 90%.

However, once we try and increase the specificity, we realize that the ideal threshold for this base model is 0.107, which our accuracy is 0.8289. 

```{r}
fitControl=trainControl(method="repeatedcv",number=5,repeats=1) 

set.seed(124)

lambda=seq(0,.05,.001)
fit.glmnet = train(factor(y)~.,
                 data = training,
                 method = "glmnet",
                 trControl = fitControl,
                 tuneGrid = expand.grid(data.frame(alpha = 1, lambda = lambda)))
fit.glmnet

plot(fit.glmnet)
opt.pen= fit.glmnet$finalModel$lambdaOpt
coef(fit.glmnet$finalModel, opt.pen)
```

```{r}
training2 = training[,-c(1,5,14)]
pen.model1 = glm(factor(y)~., data = training2, family = "binomial")
summary(pen.model1)
vif(pen.model1)
```


```{r}
# Generate an ROC curve to help us determine the best threshold
fit.glmnet_predictions = predict(fit.glmnet, test, type = "prob")$yes
fit.glmnet_roc = roc(response = test$y, predictor = fit.glmnet_predictions, levels = c("no", "yes"))
auc(fit.glmnet_roc)
plot(fit.glmnet_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.107
fit.glmnet_predictions_categorical = factor(ifelse(predict(fit.glmnet, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = fit.glmnet_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```


### Stepwise Feature Selection

AUROC:          0.9087
AIC:            15201.86
Accuracy:       0.8087
Sensitivity:    0.7991
Specificity:    0.8808

Note that because we have such unbalanced data, our accuracy is always expected to be high. Only 10% of the results were "yes".

However, once we try and increase the specificity, we realize that the ideal threshold for this base model is 0.093, which our accuracy is 0.8087.

```{r}
set.seed(124)
fit.step  = glm(factor(y) ~., data = training, family = binomial) %>%
  stepAIC(trace = FALSE)
summary(fit.step)

coef(fit.step)
vif(fit.step)

# Generate an ROC curve to help us determine the best threshold
fit.step_predictions = predict(fit.step, test, type = "response")
fit.step_roc = roc(response = test$y, predictor = fit.step_predictions, levels = c("no", "yes"))
auc(fit.step_roc)
plot(fit.step_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.093
fit.step_predictions_categorical = factor(ifelse(predict(fit.step, test, "response") >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = fit.step_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```

### Manual Stepwise

NOTE: The final model was produced elsewhere through a manual stepping process as some of the automated routines failed

AUROC:          0.9045
AIC:            15484.51
Accuracy:       0.8188
Sensitivity:    0.8137
Specificity:    0.8569 
Prevalence:     0.8831
PPV:            0.9806
NPV:            0.3673

Note that because we have such unbalanced data, our accuracy is always expected to be high. Only 10% of the results were "yes".

However, once we try and increase the specificity, we realize that the ideal threshold for this base model is 0.093, which our accuracy is 0.8087.

```{r}
set.seed(124)
stepwiseResults = read.csv("Stepwise Regression Results.csv")

ggplot(stepwiseResults, aes(x = reorder(Variable.Added, AIC, decreasing = T), y = AIC)) + 
  geom_point(size = 3) +
  labs(title = "AIC Metric with Additional Variables being Added", x= "Variable Added", y = "AIC") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

logit_step = glm(factor(y) ~ housing + contact + month + duration + poutcome , data = training, family = "binomial")
summary(logit_step)
vif(logit_step)

# Generate an ROC curve to help us determine the best threshold
logit_step_predictions = predict(logit_step, test, type = "response")
logit_step_roc = roc(response = test$y, predictor = logit_step_predictions, levels = c("no", "yes"))
auc(logit_step_roc)
plot(logit_step_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.101
logit_step_predictions_categorical = factor(ifelse(predict(logit_step, test, "response") >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = logit_step_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```

### AIC Comparison 
```{r}
AIC(model1)
AIC(adj.model1)
AIC(pen.model1)
AIC(fit.step)
AIC(logit_step)
```


```{r}
# Create a nice looking table
tbl_regression(logit_step, exponentiate = TRUE) %>% 
  as_gt() %>% 
  gt::tab_options(table.font.size = 10)
```


## Objective 2

### EDA
```{r}
# make new numeric column for "y" column
bank$y_num = num(ifelse(bank$y == "yes",1,0))

## Age
ggplot(bank,aes(x=age,y=y_num, color = marital))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE) + ggtitle("Loess Plot for Age vs. Subscriptions vs. Marital Status")

ggplot(bank,aes(x=age,y=y_num, color = education))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE) + ggtitle("Loess Plot for Age vs. Subscriptions vs. Education") # no difference 

ggplot(bank,aes(x=age,y=y_num, color = housing))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE) + ggtitle("Loess Plot for Age vs. Subscriptions vs. Housing")

ggplot(bank,aes(x=age,y=y_num, color = loan))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)+ ggtitle("Loess Plot for Age vs. Subscriptions vs. Loan")

## Balance
ggplot(bank,aes(x=balance,y=y_num, color = marital))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE) + ggtitle("Loess Plot for Balance vs. Subscriptions vs. Marital")

ggplot(bank,aes(x=balance,y=y_num, color = housing))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE) + ggtitle("Loess Plot for Balance vs. Subscriptions vs. Housing")# no difference

ggplot(bank,aes(x=balance,y=y_num, color = education))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE) + ggtitle("Loess Plot for Balance vs. Subscriptions vs. Education")

ggplot(bank,aes(x=balance,y=y_num, color = loan))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE) + ggtitle("Loess Plot for Balance vs. Subscriptions vs. Loan")

## Duration
ggplot(bank,aes(x=duration,y=y_num, color = marital))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE) + ggtitle("Loess Plot for Duration vs. Subscriptions vs. Marital")

ggplot(bank,aes(x=duration,y=y_num, color = housing))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)+ ggtitle("Loess Plot for Duration vs. Subscriptions vs. Housing")

ggplot(bank,aes(x=duration,y=y_num, color = education))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE)+ ggtitle("Loess Plot for Duration vs. Subscriptions vs. Education")

ggplot(bank,aes(x=duration,y=y_num, color = loan))+geom_point()+
  geom_smooth(method="loess",size=1,span=.75, se = FALSE) + ggtitle("Loess Plot for Duration vs. Subscriptions vs. Loan")

## Pdays
ggplot(bank,aes(x=pdays,y=y_num, color = marital))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE) + ggtitle("Loess Plot for Previous Days vs. Subscriptions vs. Marital")

ggplot(bank,aes(x=pdays,y=y_num, color = housing))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE) + ggtitle("Loess Plot for Previous Days vs. Subscriptions vs. Housing")

ggplot(bank,aes(x=pdays,y=y_num, color = education))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE) + ggtitle("Loess Plot for Previous Days vs. Subscriptions vs. Education")

ggplot(bank,aes(x=pdays,y=y_num, color = loan))+geom_point()+
  geom_smooth(method="loess",size=1,span=1, se = FALSE) + ggtitle("Loess Plot for Previous Days vs. Subscriptions vs. Loan") 

bank = bank[,-c(18)] # remove y_num from dataset

ggplot(bank, aes(x = poutcome, y = duration, fill = y)) +
  geom_boxplot() + ggtitle("Boxplot for Previous Outcome vs. Duration by Subscription Outcome")

ggplot(bank, aes(x =month, y = duration, fill = y)) +
  geom_boxplot() + ggtitle("Boxplot for Month vs. Duration by Subscription Outcome")

ggplot(bank, aes(x =marital, y = duration, fill = y)) +
  geom_boxplot() + ggtitle("Boxplot for Marital Status vs. Duration by Subscription Outcome")

ggplot(bank, aes(x = housing, y = duration, fill = y)) +
  geom_boxplot() + ggtitle("Boxplot for Housing vs. Duration by Subscription Outcome")

ggplot(bank, aes(x =month, y = log(balance), fill = y)) +
  geom_boxplot() + ggtitle("Boxplot for Month vs. log(Balance) by Subscription Outcome")

ggplot(bank, aes(x = housing, y = log(balance), fill = y)) +
  geom_boxplot() + ggtitle("Boxplot for Housing vs. log(Balance) by Subscription Outcome")

ggplot(bank, aes(x = housing, y = log(campaign), fill = y)) +
  geom_boxplot() + ggtitle("Boxplot for Housing vs. log(Campaign) by Subscription Outcome")

ggplot(bank, aes(x = education, y = log(balance), fill = y)) +
  geom_boxplot() + ggtitle("Boxplot for Education vs. log(Balance) by Subscription Outcome")

ggplot(bank, aes(x = poutcome, y = log(previous), fill = y)) +
  geom_boxplot() + ggtitle("Boxplot for Previous Outcome vs. log(Previous) by Subscription Outcome")
```

### 1. More complicated logistic regression model

AUROC:          0.9149
AIC:            14080.66
Accuracy:       0.8178          
Sensitivity:    0.8109          
Specificity:    0.8701           
Prevalence:     0.8831
PPV:            0.9792          
NPV:            0.3786          

```{r}
logit_complex = glm(factor(y) ~ poutcome +  log(duration + 1) + poutcome:log(duration + 1) + month + month:log(duration + 1) + contact + housing + housing:log(duration + 1) + job + campaign + campaign:log(duration + 1) + loan + loan:log(duration + 1) + marital + marital + education + day + balance + month:balance, 
                    data = training, family = "binomial")

summary(logit_complex)

# Generate an ROC curve to help us determine the best threshold
logit_complex_predictions = predict(logit_complex, test, type = "response")
logit_complex_roc = roc(response = test$y, predictor = logit_complex_predictions, levels = c("no", "yes"))
auc(logit_complex_roc)
plot(logit_complex_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.118
logit_complex_predictions_categorical = factor(ifelse(predict(logit_complex, test, "response") >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = logit_complex_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))

AIC(logit_complex)
anova(logit_complex, test="Chisq")
```

### 2. LDA/QDA

```{r}
training %>% ggplot(aes(x =age,y = balance, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =age,y = day, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =age,y = duration, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =age,y = campaign, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =log(balance),y = day, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =log(balance),y = duration, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =log(balance),y = log(campaign), color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =day,y = duration, color = as.factor(y))) + 
  geom_point()+geom_density_2d()

training %>% ggplot(aes(x =day,y = campaign, color = as.factor(y))) + 
  geom_point()+geom_density_2d()
```
#### LDA 

AUROC:          0.9117
Accuracy:       0.826                   
Sensitivity:    0.8217                    
Specificity:    0.8581           
Prevalence:     0.8831
PPV:            0.9776          
NPV:            0.3893  

```{r}
set.seed(1234)
fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
lda_base = train(factor(y) ~ ., data = training, method = "lda", trControl = fitControl, metric = "logLoss")
summary(lda_base)

# Generate an ROC curve to help us determine the best threshold
lda_base_predictions = predict(lda_base, test, type = "prob")$yes
lda_base_roc = roc(response = test$y, predictor = lda_base_predictions, levels = c("no", "yes"))
auc(lda_base_roc)
plot(lda_base_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.045
lda_base_predictions_categorical = factor(ifelse(predict(lda_base, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = lda_base_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```
#### QDA

NOTE: QDA does not perform very well here. The optimal threshold was 0 which returns NaN's in certain performance metrics

AUROC:          0.838
Accuracy:       0.1169                    
Sensitivity:    0.0             
Specificity:    1.0         
Prevalence:     0.8831
PPV:            NaN       
NPV:            0.1169          

```{r}
set.seed(1234)
fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
qda_base = train(factor(y) ~ ., data = training, method = "qda", trControl = fitControl, metric = "logLoss")
summary(qda_base)

# Generate an ROC curve to help us determine the best threshold
qda_base_predictions = predict(qda_base, test, type = "prob")$yes
qda_base_roc = roc(response = test$y, predictor = qda_base_predictions, levels = c("no", "yes"))
auc(qda_base_roc)
plot(qda_base_roc, print.thres = "best", col = "black")

# Predict
threshold = 0
qda_base_predictions_categorical = factor(ifelse(predict(qda_base, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = qda_base_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```


### 3. Non-parametric model

#### KNN Model

AUROC:          0.7963
Accuracy:       0.8084                   
Sensitivity:    0.8286                   
Specificity:    0.6564                    
Prevalence:     0.8831
PPV:            0.9479                   
NPV:            0.3365         

```{r}
## KNN 
set.seed(1234)
fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
knn.base = train(factor(y) ~ ., data = training, method = "knn", trControl = fitControl, metric = "logLoss")

# Generate an ROC curve to help us determine the best threshold
knn.base_predictions = predict(knn.base, test, type = "prob")$yes
knn.base_roc = roc(response = test$y, predictor = knn.base_predictions, levels = c("no", "yes"))
auc(knn.base_roc)
plot(knn.base_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.211
knn.base_predictions_categorical = factor(ifelse(predict(knn.base, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = knn.base_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```

#### Random Forest Model

AUROC:         0.9281 
Accuracy:      0.8363           
Sensitivity:   0.8267           
Specificity:   0.9086            
Prevalence:    0.8831
PPV:           0.9856           
NPV:           0.4098

```{r}
## Random Forest
set.seed(1234)
fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
rf.base = train(factor(y) ~ ., data = training, method = "rf", trControl = fitControl, metric = "logLoss")
summary(rf.base)

# Generate an ROC curve to help us determine the best threshold
rf.base_predictions = predict(rf.base, test, type = "prob")$yes
rf.base_roc = roc(response = test$y, predictor = rf.base_predictions, levels = c("no", "yes"))
auc(rf.base_roc)
plot(rf.base_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.123
rf.base_predictions_categorical = factor(ifelse(predict(rf.base, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = rf.base_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```

#### eXtreme Gradient Boosting 

AUROC:          0.9333   
Accuracy:       0.834          
Sensitivity:    0.8228          
Specificity:    0.9187           
Prevalence:     0.8831
PPV:            0.9871          
NPV:            0.4071

```{r, message=F, warning=F}
## XGB
set.seed(1234)
fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 1, classProbs = TRUE, summaryFunction = mnLogLoss)
xgb.base = train(factor(y) ~ ., data = training, method = "xgbTree", trControl = fitControl, metric = "logLoss")
summary(xgb.base)

# Generate an ROC curve to help us determine the best threshold
xgb.base_predictions = predict(xgb.base, test, type = "prob")$yes
xgb.base_roc = roc(response = test$y, predictor = xgb.base_predictions, levels = c("no", "yes"))
auc(xgb.base_roc)
plot(xgb.base_roc, print.thres = "best", col = "black")

# Predict
threshold = 0.096
xgb.base_predictions_categorical = factor(ifelse(predict(xgb.base, test, type = "prob")$yes >= threshold, "yes", "no"), levels = c("no", "yes"))
confusionMatrix(data = xgb.base_predictions_categorical, reference = factor(test$y, levels = c("no", "yes")))
```

### Check All Models AIC
```{r}
AIC(model1)
AIC(adj.model1)
AIC(pen.model1)
AIC(fit.step)
AIC(logit_step)
AIC(logit_complex)
```